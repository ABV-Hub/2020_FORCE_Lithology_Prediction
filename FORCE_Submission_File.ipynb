{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FORCE_Submission_File.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4wK_1Sp5oZz"
      },
      "source": [
        "#importing required libraries and packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import numpy.random as nr\n",
        "import matplotlib\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn import preprocessing\n",
        "import sklearn.model_selection as ms\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff7CdOKkPise",
        "outputId": "83bd93a8-0312-4c48-fb6b-0fbeca55cde4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#printing out versions of all packages and libraries and used\n",
        "\n",
        "print(f'pandas version is: {pd.__version__}')\n",
        "print(f'numpy version is: {np.__version__}')\n",
        "print(f'matplotlib version is: {matplotlib.__version__}')\n",
        "print(f'sklearn version is: {sklearn.__version__}')\n",
        "print(f'xgboost version is: {xgb.__version__}')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pandas version is: 1.1.2\n",
            "numpy version is: 1.18.5\n",
            "matplotlib version is: 3.2.2\n",
            "sklearn version is: 0.22.2.post1\n",
            "xgboost version is: 0.90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1HHu00J6gBZ"
      },
      "source": [
        "#all helper functions used\n",
        "\n",
        "def drop_columns(traindata, *args):\n",
        "\n",
        "    '''\n",
        "    function used to drop columns.\n",
        "    args:: \n",
        "      data:  dataframe to be operated on\n",
        "      *args: a list of columns to be dropped from the dataframe\n",
        "\n",
        "    return: returns a dataframe with the columns dropped\n",
        "    '''\n",
        "    \n",
        "    columns = []\n",
        "    for _ in args:\n",
        "        columns.append(_)\n",
        "        \n",
        "    data = data.drop(columns, axis=1)\n",
        "        \n",
        "    return data\n",
        " \n",
        "def process(data):\n",
        "\n",
        "    '''\n",
        "    function to process dataframe by replacing missing, infinity values with -999\n",
        "\n",
        "    args:: \n",
        "      data:  dataframe to be operated on\n",
        "    \n",
        "    returns dataframe with replaced values\n",
        "    '''\n",
        "    \n",
        "    cols = list(data.columns)\n",
        "    for _ in cols:\n",
        "\n",
        "        data[_] = np.where(data[_] == np.inf, -999, data[_])\n",
        "        data[_] = np.where(data[_] == np.nan, -999, data[_])\n",
        "        data[_] = np.where(data[_] == -np.inf, -999, data[_])\n",
        "        \n",
        "    return data\n",
        " \n",
        "def show_evaluation(pred, true):\n",
        "\n",
        "  '''\n",
        "\n",
        "  function to show model performance and evaluation\n",
        "  args:\n",
        "    pred: predicted value(a list)\n",
        "    true: actual values (a list)\n",
        "\n",
        "  prints the custom metric performance, accuracy and F1 score of predictions\n",
        "\n",
        "  '''\n",
        "\n",
        "  print(f'Default score: {score(true.values, pred)}')\n",
        "  print(f'Accuracy is: {accuracy_score(true, pred)}')\n",
        "  print(f'F1 is: {f1_score(pred, true.values, average=\"weighted\")}')\n",
        "\n",
        "\n",
        "#Paulo Bestagini's feature augmentation technique from SEG 2016 ML competition\n",
        "#Link : https://github.com/seg/2016-ml-contest/tree/master/ispl\n",
        "\n",
        "# Feature windows concatenation function\n",
        "def augment_features_window(X, N_neig):\n",
        "    \n",
        "    # Parameters\n",
        "    N_row = X.shape[0]\n",
        "    N_feat = X.shape[1]\n",
        " \n",
        "    # Zero padding\n",
        "    X = np.vstack((np.zeros((N_neig, N_feat)), X, (np.zeros((N_neig, N_feat)))))\n",
        " \n",
        "    # Loop over windows\n",
        "    X_aug = np.zeros((N_row, N_feat*(2*N_neig+1)))\n",
        "    for r in np.arange(N_row)+N_neig:\n",
        "        this_row = []\n",
        "        for c in np.arange(-N_neig,N_neig+1):\n",
        "            this_row = np.hstack((this_row, X[r+c]))\n",
        "        X_aug[r-N_neig] = this_row\n",
        " \n",
        "    return X_aug\n",
        " \n",
        "# Feature gradient computation function\n",
        "def augment_features_gradient(X, depth):\n",
        "    \n",
        "    # Compute features gradient\n",
        "    d_diff = np.diff(depth).reshape((-1, 1))\n",
        "    d_diff[d_diff==0] = 0.001\n",
        "    X_diff = np.diff(X, axis=0)\n",
        "    X_grad = X_diff / d_diff\n",
        "        \n",
        "    # Compensate for last missing value\n",
        "    X_grad = np.concatenate((X_grad, np.zeros((1, X_grad.shape[1]))))\n",
        "    \n",
        "    return X_grad\n",
        " \n",
        "# Feature augmentation function\n",
        "def augment_features(X, well, depth, N_neig=1):\n",
        "    \n",
        "    # Augment features\n",
        "    X_aug = np.zeros((X.shape[0], X.shape[1]*(N_neig*2+2)))\n",
        "    for w in np.unique(well):\n",
        "        w_idx = np.where(well == w)[0]\n",
        "        X_aug_win = augment_features_window(X[w_idx, :], N_neig)\n",
        "        X_aug_grad = augment_features_gradient(X[w_idx, :], depth[w_idx])\n",
        "        X_aug[w_idx, :] = np.concatenate((X_aug_win, X_aug_grad), axis=1)\n",
        "    \n",
        "    # Find padded rows\n",
        "    padded_rows = np.unique(np.where(X_aug[:, 0:7] == np.zeros((1, 7)))[0])\n",
        "    \n",
        "    return X_aug, padded_rows\n",
        "\n",
        "def score(y_true, y_pred):\n",
        "\n",
        "    '''\n",
        "    custom metric used for evaluation\n",
        "    args:\n",
        "      y_true: actual prediction\n",
        "      y_pred: predictions made\n",
        "    '''\n",
        "\n",
        "    S = 0.0\n",
        "    y_true = y_true.astype(int)\n",
        "    y_pred = y_pred.astype(int)\n",
        "    for i in range(0, y_true.shape[0]):\n",
        "        S -= A[y_true[i], y_pred[i]]\n",
        "    return S/y_true.shape[0]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMZi5ywWUCQV",
        "outputId": "ea7011ce-6119-4a87-ba89-d3e22c2622e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSQfmlIWxBM8"
      },
      "source": [
        "#should be edited to the present working directory of the user\n",
        "PWD = '/content/drive/My Drive/FORCE-Lithology-Prediction/'"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cLS1yO56iT_"
      },
      "source": [
        "#importing penaltry matrix used for evaluation and train and test files\n",
        "A = np.load(PWD + 'penalty_matrix.npy')\n",
        "\n",
        "train = pd.read_csv(PWD + 'Train.csv', sep=';')\n",
        "\n",
        "test = pd.read_csv(PWD + 'Test.csv', sep=';')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQSZM0glXhPD"
      },
      "source": [
        "class Model():\n",
        "\n",
        "    '''\n",
        "    class to lithology prediction\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, train, test):\n",
        "\n",
        "        '''\n",
        "        takes in the train and test dataframes\n",
        "        '''\n",
        "        \n",
        "        self.train = train\n",
        "        self.test = test\n",
        "\n",
        "        \n",
        "    def __call__(self, plot = True):\n",
        "\n",
        "      return self.fit(plot)\n",
        "\n",
        "    def preprocess(self, train, test):\n",
        "\n",
        "        '''\n",
        "        method to prepare datasets for training and predictions\n",
        "        accepts both the train and test dataframes as arguments\n",
        "\n",
        "        returns the prepared train, test datasets along with the\n",
        "        lithology labels and numbers which is needed for preparing\n",
        "        the submission file\n",
        "\n",
        "        '''\n",
        "\n",
        "        #concatenating both train and test datasets for easier and uniform processing\n",
        "\n",
        "        ntrain = train.shape[0]\n",
        "        ntest = test.shape[0]\n",
        "        target = train.FORCE_2020_LITHOFACIES_LITHOLOGY.copy()\n",
        "        df = pd.concat((train, test)).reset_index(drop=True)\n",
        "\n",
        "        #mapping the lithology labels to ordinal values for better modelling\n",
        "\n",
        "        lithology = train['FORCE_2020_LITHOFACIES_LITHOLOGY']\n",
        " \n",
        "        lithology_numbers = {30000: 0,\n",
        "                        65030: 1,\n",
        "                        65000: 2,\n",
        "                        80000: 3,\n",
        "                        74000: 4,\n",
        "                        70000: 5,\n",
        "                        70032: 6,\n",
        "                        88000: 7,\n",
        "                        86000: 8,\n",
        "                        99000: 9,\n",
        "                        90000: 10,\n",
        "                        93000: 11}\n",
        "        \n",
        "        lithology1 = lithology.map(lithology_numbers)\n",
        "\n",
        "        #implementing Bestagini's augmentation procedure\n",
        "\n",
        "        train_well = train.WELL.values\n",
        "        train_depth = train.DEPTH_MD.values\n",
        "        \n",
        "        test_well = test.WELL.values\n",
        "        test_depth = test.DEPTH_MD.values  '''to be continued...\n",
        "        #this was done here for ease as the datasets would undergo some transformations\n",
        "        #that would make it uneasy to perform the augmentation technique'''\n",
        "\n",
        "        \n",
        "\n",
        "        print(f'shape of concatenated dataframe before dropping columns {df.shape}')\n",
        "\n",
        "        cols = ['FORCE_2020_LITHOFACIES_CONFIDENCE', 'SGR', 'DTS', 'RXO', 'ROPA'] #columns to be dropped\n",
        "        df = drop_columns(df, *cols)\n",
        "        print(f'shape of dataframe after dropping columns {df.shape}')\n",
        "        print(f'{cols} were dropped')\n",
        "\n",
        "        #Label encoding the GROUP, FORMATION and WELLS features as these improved the performance of the models on validations\n",
        "\n",
        "        df['GROUP_encoded'] = df['GROUP'].astype('category')\n",
        "        df['GROUP_encoded'] = df['GROUP_encoded'].cat.codes \n",
        "        df['FORMATION_encoded'] = df['FORMATION'].astype('category')\n",
        "        df['FORMATION_encoded'] = df['FORMATION_encoded'].cat.codes\n",
        "        df['WELL_encoded'] = df['WELL'].astype('category')\n",
        "        df['WELL_encoded'] = df['WELL_encoded'].cat.codes\n",
        "        print(f'shape of dataframe after label encoding columns {df.shape}')\n",
        "\n",
        "\n",
        "        #FURTHER PREPRATION TO SPLIT DATAFRAME INTO TRAIN AND TEST DATASETS AFTER PREPRATION\n",
        "        print(f'Splitting concatenated dataframe into training and test datasets...')\n",
        "        df = df.drop(['WELL', 'GROUP', 'FORMATION'], axis=1)\n",
        "        print(df.shape)\n",
        "        \n",
        "        df = df.fillna(-999)\n",
        "        df = process(df)\n",
        "        data = df.copy()\n",
        "        \n",
        "        train2 = data[:ntrain].copy()\n",
        "        train2.drop(['FORCE_2020_LITHOFACIES_LITHOLOGY'], axis=1, inplace=True)\n",
        "        \n",
        "        test2 = data[ntrain:(ntest+ntrain)].copy()\n",
        "        test2.drop(['FORCE_2020_LITHOFACIES_LITHOLOGY'], axis=1, inplace=True)\n",
        "        test2 = test2.reset_index(drop=True)\n",
        "\n",
        "        traindata = train2\n",
        "        testdata = test2\n",
        "\n",
        "        print(f'Shape of train and test datasets before augmentation {traindata.shape, testdata.shape}')\n",
        " \n",
        "        traindata1, padded_rows = augment_features(pd.DataFrame(traindata).values, train_well, train_depth)\n",
        "        testdata1, padded_rows = augment_features(pd.DataFrame(testdata).values, test_well, test_depth)\n",
        "        \n",
        "        print(f'Shape of train and test datasets after augmentation {traindata.shape, testdata.shape}')\n",
        "    \n",
        "        return traindata1, testdata1, lithology1, lithology_numbers\n",
        "\n",
        "    \n",
        "    def fit(self, plot):\n",
        "\n",
        "      '''\n",
        "      method to train model and make predictions\n",
        "\n",
        "      returns the test predictions, trained model, and lithology numbers used for making the submission file\n",
        "      '''\n",
        "\n",
        "      traindata1, testdata1, lithology1, lithology_numbers = self.preprocess(self.train, self.test)\n",
        "\n",
        "      #using a 10-fold stratified cross-validation technique and seting the shuffle parameter to true\n",
        "      #as this improved the validation performance better\n",
        "\n",
        "      split = 10\n",
        "      kf = StratifiedKFold(n_splits=split, shuffle=True)\n",
        "  \n",
        "      open_test = np.zeros((len(testdata1), 12))\n",
        "      \n",
        "      model = XGBClassifier(n_estimators=100, max_depth=10, booster='gbtree',\n",
        "                            objective='multi:softprob', learning_rate=0.1, random_state=50,\n",
        "                            subsample=0.9, colsample_bytree=0.9, tree_method='gpu_hist',\n",
        "                            eval_metric='mlogloss', verbose=2020, reg_lambda=1500)\n",
        "      \n",
        " \n",
        "      i = 1\n",
        "      for (train_index, test_index) in kf.split(pd.DataFrame(traindata1), pd.DataFrame(lithology1)):\n",
        "        X_train, X_test = pd.DataFrame(traindata1).iloc[train_index], pd.DataFrame(traindata1).iloc[test_index]\n",
        "        Y_train, Y_test = pd.DataFrame(lithology1).iloc[train_index],pd.DataFrame(lithology1).iloc[test_index]\n",
        "    \n",
        "        model.fit(X_train, Y_train, early_stopping_rounds=100, eval_set=[(X_test, Y_test)], verbose=100)\n",
        "        prediction = model.predict(X_test)\n",
        "        print(show_evaluation(prediction, Y_test))\n",
        " \n",
        "        print(f'-----------------------FOLD {i}---------------------')\n",
        "        i+=1\n",
        " \n",
        "        open_test += model.predict_proba(pd.DataFrame(testdata1))\n",
        "      \n",
        "      open_test= pd.DataFrame(open_test/split)\n",
        "    \n",
        "      open_test = np.array(pd.DataFrame(open_test).idxmax(axis=1))\n",
        " \n",
        "      print('---------------CROSS VALIDATION COMPLETE')\n",
        "      print('----------------TEST EVALUATION------------------')\n",
        "\n",
        "                  \n",
        "      if plot: self.plot_feat_imp(model)\n",
        "      return open_test, model, lithology_numbers\n",
        "              \n",
        "              \n",
        "    def plot_feat_imp(self, model):\n",
        "        feat_imp = pd.Series(model.feature_importances_).sort_values(ascending=False)\n",
        "        plt.figure(figsize=(12,8))\n",
        "        feat_imp.plot(kind='bar', title='Feature Importances')\n",
        "        plt.ylabel('Feature Importance Score')\n",
        "\n",
        "    def make_submission_file(self, filename):\n",
        "\n",
        "      '''\n",
        "      method to train model, make prediction and create submission file\n",
        "      args::\n",
        "        filename: name to save submission file as (string)\n",
        "      '''\n",
        "\n",
        "      self.filename = filename\n",
        "\n",
        "      prediction, model, lithology_numbers = self.fit(plot=False)\n",
        " \n",
        "      path = '/content/drive/My Drive/FORCE-Lithology-Prediction/'\n",
        "    \n",
        "      test = pd.read_csv('/content/drive/My Drive/FORCE-Lithology-Prediction/Test.csv', sep=';')\n",
        "      \n",
        "      category_to_lithology = {y:x for x,y in lithology_numbers.items()}\n",
        "      test_prediction_for_submission = np.vectorize(category_to_lithology.get)(prediction)\n",
        "      np.savetxt(path+filename+'.csv', test_prediction_for_submission, header='lithology', fmt='%i')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3dOrluJWtPM",
        "outputId": "eee77bac-d43e-4042-8d1a-3c8cd763652a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        }
      },
      "source": [
        "func_= Model(train, test)\n",
        "prediction, model, redundant = func_()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1307297, 29)\n",
            "(1307297, 24)\n",
            "(1307297, 27)\n",
            "(1307297, 24)\n",
            "(1170511, 23) (136786, 23)\n",
            "(1170511, 23) (136786, 23)\n",
            "(1170511, 92) (136786, 92)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:2.18383\n",
            "Will train until validation_0-mlogloss hasn't improved in 100 rounds.\n",
            "Default score: None\n",
            "Accuracy is: 0.7744730511092581\n",
            "F1 is: 0.804123456968454\n",
            "None\n",
            "-----------------------FOLD 1---------------------\n",
            "[0]\tvalidation_0-mlogloss:2.18405\n",
            "Will train until validation_0-mlogloss hasn't improved in 100 rounds.\n",
            "Default score: None\n",
            "Accuracy is: 0.7736542191010756\n",
            "F1 is: 0.8029184634763253\n",
            "None\n",
            "-----------------------FOLD 2---------------------\n",
            "---------------CROSS VALIDATION COMPLETE\n",
            "----------------TEST EVALUATION------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sueoRdaykxzp",
        "outputId": "c3d3c4f5-7c43-4dc9-fb14-5fe5aab0ef64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "prediction"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 2, ..., 1, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd45KJLVk3Ka"
      },
      "source": [
        "func_= Model(train, test)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRywwBE3mCb7",
        "outputId": "368a667f-309b-4301-eee9-559e91da29aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "func_.make_submission_file('testing3')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1307297, 29)\n",
            "(1307297, 24)\n",
            "(1307297, 27)\n",
            "(1307297, 24)\n",
            "(1170511, 23) (136786, 23)\n",
            "(1170511, 23) (136786, 23)\n",
            "(1170511, 92) (136786, 92)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:2.16454\n",
            "Will train until validation_0-mlogloss hasn't improved in 100 rounds.\n",
            "[99]\tvalidation_0-mlogloss:0.321188\n",
            "Default score: None\n",
            "Accuracy is: 0.8938420531046031\n",
            "F1 is: 0.897622820476685\n",
            "None\n",
            "-----------------------FOLD 1---------------------\n",
            "[0]\tvalidation_0-mlogloss:2.16442\n",
            "Will train until validation_0-mlogloss hasn't improved in 100 rounds.\n",
            "[99]\tvalidation_0-mlogloss:0.322216\n",
            "Default score: None\n",
            "Accuracy is: 0.8932345729639217\n",
            "F1 is: 0.8973209272967764\n",
            "None\n",
            "-----------------------FOLD 2---------------------\n",
            "[0]\tvalidation_0-mlogloss:2.16407\n",
            "Will train until validation_0-mlogloss hasn't improved in 100 rounds.\n",
            "[99]\tvalidation_0-mlogloss:0.316318\n",
            "Default score: None\n",
            "Accuracy is: 0.8958488180365823\n",
            "F1 is: 0.8997252967497092\n",
            "None\n",
            "-----------------------FOLD 3---------------------\n",
            "[0]\tvalidation_0-mlogloss:2.1647\n",
            "Will train until validation_0-mlogloss hasn't improved in 100 rounds.\n",
            "[99]\tvalidation_0-mlogloss:0.318528\n",
            "Default score: None\n",
            "Accuracy is: 0.8950286627196692\n",
            "F1 is: 0.8988137273372748\n",
            "None\n",
            "-----------------------FOLD 4---------------------\n",
            "[0]\tvalidation_0-mlogloss:2.16436\n",
            "Will train until validation_0-mlogloss hasn't improved in 100 rounds.\n",
            "[99]\tvalidation_0-mlogloss:0.319446\n",
            "Default score: None\n",
            "Accuracy is: 0.8940205551426301\n",
            "F1 is: 0.8979635312540762\n",
            "None\n",
            "-----------------------FOLD 5---------------------\n",
            "[0]\tvalidation_0-mlogloss:2.16453\n",
            "Will train until validation_0-mlogloss hasn't improved in 100 rounds.\n",
            "[99]\tvalidation_0-mlogloss:0.320885\n",
            "Default score: None\n",
            "Accuracy is: 0.8940034685735277\n",
            "F1 is: 0.8980320740215644\n",
            "None\n",
            "-----------------------FOLD 6---------------------\n",
            "[0]\tvalidation_0-mlogloss:2.16417\n",
            "Will train until validation_0-mlogloss hasn't improved in 100 rounds.\n",
            "[99]\tvalidation_0-mlogloss:0.316964\n",
            "Default score: None\n",
            "Accuracy is: 0.8949005134514015\n",
            "F1 is: 0.8987979564166124\n",
            "None\n",
            "-----------------------FOLD 7---------------------\n",
            "[99]\tvalidation_0-mlogloss:0.318859\n",
            "Default score: None\n",
            "Accuracy is: 0.8943793730937797\n",
            "F1 is: 0.8983449074905256\n",
            "None\n",
            "-----------------------FOLD 8---------------------\n",
            "[0]\tvalidation_0-mlogloss:2.16474\n",
            "Will train until validation_0-mlogloss hasn't improved in 100 rounds.\n",
            "[99]\tvalidation_0-mlogloss:0.320802\n",
            "Default score: None\n",
            "Accuracy is: 0.8941914208336537\n",
            "F1 is: 0.8982685842808044\n",
            "None\n",
            "-----------------------FOLD 9---------------------\n",
            "[0]\tvalidation_0-mlogloss:2.16406\n",
            "Will train until validation_0-mlogloss hasn't improved in 100 rounds.\n",
            "[99]\tvalidation_0-mlogloss:0.315226\n",
            "Default score: None\n",
            "Accuracy is: 0.8955412597927399\n",
            "F1 is: 0.8994021365003589\n",
            "None\n",
            "-----------------------FOLD 10---------------------\n",
            "---------------CROSS VALIDATION COMPLETE\n",
            "----------------TEST EVALUATION------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmxsGsBWmtAp",
        "outputId": "4f38bbe3-2ca4-4ab3-a3e4-c89b74e6e648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "a = pd.read_csv('/content/drive/My Drive/FORCE-Lithology-Prediction/testing2.csv')\n",
        " \n",
        "a['# lithology'].value_counts()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65000    99960\n",
              "30000    25604\n",
              "65030     5995\n",
              "70000     4537\n",
              "80000      435\n",
              "99000      157\n",
              "90000       76\n",
              "86000       12\n",
              "70032       10\n",
              "Name: # lithology, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVhwlsFZs_-b",
        "outputId": "25c79e2a-5b26-4792-b727-347bd16bb959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "a = pd.read_csv('/content/drive/My Drive/FORCE-Lithology-Prediction/testing3.csv')\n",
        " \n",
        "a['# lithology'].value_counts()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65000    97195\n",
              "30000    23976\n",
              "65030     8970\n",
              "70000     4808\n",
              "99000      985\n",
              "80000      425\n",
              "90000      405\n",
              "86000       22\n",
              "Name: # lithology, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IbJ6srptAp_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}